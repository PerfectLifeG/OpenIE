# -*- coding: utf-8 -*-
"""
åœ¨ dev ä¸Šè®¡ç®— NER æŒ‡æ ‡ï¼š
æ¨¡å¼1ï¼šä¸¥æ ¼æ¨¡å¼ - (name, coarse_type, fine_type) ä¸‰ä¸ªéƒ½å¯¹
æ¨¡å¼2ï¼šä¸­ç­‰æ¨¡å¼ - (name, coarse_type) ä¸¤ä¸ªå¯¹
æ¨¡å¼3ï¼šå®½æ¾æ¨¡å¼ - åªå¯¹ name
"""

import json

def _load_jsonl_or_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return [json.loads(line) for line in f]
    except json.decoder.JSONDecodeError:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)


def _to_keys(sample, mode="strict"):
    """
    æ ¹æ®æ¨¡å¼ç”Ÿæˆä¸åŒçš„key
    mode: "strict" - (name, coarse_type, fine_type)
          "medium" - (name, coarse_type)
          "loose"  - name
    """
    keys = set()
    for e in sample.get("entities", []):
        if isinstance(e, dict):  # dictæ ¼å¼çš„NERè¾“å‡º
            subj = e.get("subject", ["", "", ""])
            obj = e.get("object", ["", "", ""])
            rel = e.get("relationship", "")

            subj_name = subj[0] if subj else ""
            obj_name = obj[0] if obj else ""

            keys.add(subj_name)
            keys.add(obj_name)
            # print(subj_name)
            # print(obj_name)
            # name = e.get("name", "")
            # ct = e.get("coarse_type", "")
            # ft = e.get("fine_type", "")
        else:  # ç®€å•å­—ç¬¦ä¸²æ ¼å¼çš„NERè¾“å‡º
            name, ct, ft = e, "", ""
            keys.add(name)


        # if mode == "strict":
        #     keys.add((name, ct, ft))  # ä¸‰ä¸ªéƒ½å¯¹
        # elif mode == "medium":
        #     keys.add((name, ct))  # ä¸¤ä¸ªå¯¹
        # elif mode == "loose":
        #     keys.add(name)  # åªå¯¹name
    return keys


def evaluate_ner(dev_gold_path, pred_path, mode="strict", error_output_path=None):
    """
    è¯„æµ‹NERæ€§èƒ½
    mode: "strict" - (name, coarse_type, fine_type) ä¸‰ä¸ªéƒ½å¯¹
          "medium" - (name, coarse_type) ä¸¤ä¸ªå¯¹
          "loose"  - åªå¯¹ name
    """
    gold = _load_jsonl_or_json(dev_gold_path)  # gold: json list
    pred = _load_jsonl_or_json(pred_path)  # pred: jsonl list

    tp = fp = fn = 0

    # æ–°å¢ï¼šé”™è¯¯åˆ†ææ•°æ®
    error_analysis = []

    for idx, (g, p) in enumerate(zip(gold, pred)):
        g_entities = g.get("output", [])
        p_entities = p.get("entities", [])

        gset = _to_keys({"entities": g_entities}, mode)
        pset = _to_keys({"entities": p_entities}, mode)

        tp_i = len(gset & pset)
        fp_i = len(pset - gset)
        fn_i = len(gset - pset)

        tp += tp_i
        fp += fp_i
        fn += fn_i

        # æ–°å¢ï¼šè®°å½•é”™è¯¯æ ·æœ¬
        if error_output_path and (fp_i > 0 or fn_i > 0):
            error_sample = {
                "index": idx,
                "sentence": g.get("sentence", ""),
                "coarse_types": g.get("coarse_types", []),
                "gold_entities": g_entities,
                "pred_entities": p_entities
            }
            error_analysis.append(error_sample)


    def prf(tp, fp, fn):
        p = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        r = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f = 2 * p * r / (p + r) if (p + r) > 0 else 0.0
        return {"precision": p, "recall": r, "f1": f}

    report = {"overall": prf(tp, fp, fn), "mode": mode}


    # æ–°å¢ï¼šä¿å­˜é”™è¯¯åˆ†æç»“æœ
    if error_output_path and error_analysis:
        with open(error_output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "error_statistics": {
                    "total_samples": len(gold),
                    "error_samples": len(error_analysis),
                    "error_rate": len(error_analysis) / len(gold),
                    "mode": mode
                },
                "error_details": error_analysis
            }, f, ensure_ascii=False, indent=2)
        print(f"âœ… é”™è¯¯åˆ†æå·²ä¿å­˜åˆ°: {error_output_path}")
        print(f"ğŸ“Š é”™è¯¯æ ·æœ¬ç»Ÿè®¡: {len(error_analysis)}/{len(gold)} ä¸ªæ ·æœ¬å­˜åœ¨é”™è¯¯")

    return report



def run():
    data_path = '/home/penglin.ge/code/HippoRAG-main/reproduce/dataset/test2.json'
    save_path = '/home/penglin.ge/code/OpenIE/outputs/test2/ner_1__home_penglin.ge_code_DoRA_commonsense_reasoning_model1.json'
    error_output_path = '/home/penglin.ge/code/OpenIE/outputs/dev2/error.json'

    # ä¸‰ç§æ¨¡å¼åˆ†åˆ«è¯„æµ‹
    modes = ["strict", "medium", "loose"]
    mode_names = {
        "strict": "ä¸¥æ ¼æ¨¡å¼ (name, coarse_type, fine_type)",
        "medium": "ä¸­ç­‰æ¨¡å¼ (name, coarse_type)",
        "loose": "å®½æ¾æ¨¡å¼ (name)"
    }

    all_reports = {}

    for mode in modes:
        print(f"\n=== {mode_names[mode]} ===")
        report = evaluate_ner(
            dev_gold_path=data_path,
            pred_path=save_path,
            mode=mode,
            error_output_path=error_output_path.replace('.json', f'_{mode}.json')
        )
        all_reports[mode] = report
        print(json.dumps(report, ensure_ascii=False, indent=2))

    # è¾“å‡ºå¯¹æ¯”ç»“æœ
    print("\n" + "=" * 50)
    print("ä¸‰ç§æ¨¡å¼å¯¹æ¯”ç»“æœ:")
    print("=" * 50)
    for mode in modes:
        overall = all_reports[mode]["overall"]
        print(
            f"{mode_names[mode]:<40} | F1: {overall['f1']:.4f} | Precision: {overall['precision']:.4f} | Recall: {overall['recall']:.4f}")


if __name__ == "__main__":
    run()